{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c758ca02",
   "metadata": {},
   "source": [
    "# N-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e8647",
   "metadata": {},
   "source": [
    "Before we move on to the probability stuff, let’s answer this question first. Why is it that we need to learn n-gram and the related probability? Well, in Natural Language Processing, or NLP for short, n-grams are used for a variety of things. Some examples include auto completion of sentences (such as the one we see in Gmail these days), auto spell check (yes, we can do that as well), and to a certain extent, we can check for grammar in a given sentence. We’ll see some examples of this later in the post when we talk about assigning probabilities to n-grams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f78ac8a",
   "metadata": {},
   "source": [
    "N-grams are continuous sequences of words or symbols, or tokens in a document. In technical terms, they can be defined as the neighboring sequences of items in a document. They come into play when we deal with text data in NLP (Natural Language Processing) tasks. They have a wide range of applications, like language models, semantic features, spelling correction, machine translation, text mining, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f3fcc5",
   "metadata": {},
   "source": [
    "N-gram is a sequence of the N-words in the modeling of NLP. Consider an example of the statement for modeling. “I love reading history books and watching documentaries”. In one-gram or unigram, there is a one-word sequence. As for the above statement, in one gram it can be “I”, “love”, “history”, “books”, “and”, “watching”, “documentaries”. In two-gram or the bi-gram, there is the two-word sequence i.e. “I love”, “love reading”, or “history books”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1454dcde",
   "metadata": {},
   "source": [
    "\"There was heavy rain\" and \"There was heavy flood\". By using experience, it can be said that the first statement is good. The N-gram language model tells that the \"heavy rain\" occurs more frequently than the \"heavy flood\". So, the first statement is more likely to occur and it will be then selected by this model. In the one-gram model, the model usually relies on that which word occurs often without pondering the previous words. In 2-gram, only the previous word is considered for predicting the current word. In 3-gram, two previous words are considered. In the N-gram language model the following probabilities are calculated:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08ee4b5",
   "metadata": {},
   "source": [
    "Summing up, ‘n’ is just a variable that can have positive integer values, including 1,2,3, and so on.’n’ basically refers to multiple.\n",
    "\n",
    "Thinking along the same lines, n-grams are classified into the following types, depending on the value that ‘n’ takes.\n",
    "\n",
    ">n\tTerm\n",
    "\n",
    ">1\tUnigram\n",
    "\n",
    ">2\tBigram\n",
    "\n",
    ">3\tTrigram\n",
    "\n",
    ">n\tn-gram\n",
    "\n",
    "As clearly depicted in the table above, when n=1, it is said to be a unigram. When n=2, it is said to be a bigram, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8197348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "sentence = 'I reside in Bengaluru.'\n",
    "n = 1\n",
    "unigrams = ngrams(sentence.split(), n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10315352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x175eed73280>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0a4e741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I',)\n",
      "('reside',)\n",
      "('in',)\n",
      "('Bengaluru.',)\n"
     ]
    }
   ],
   "source": [
    "for grams in unigrams:\n",
    "    print (grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0897de2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I', 'reside')\n",
      "('reside', 'in')\n",
      "('in', 'Bengaluru.')\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "sentence = 'I reside in Bengaluru.'\n",
    "n = 2\n",
    "bigrams = ngrams(sentence.split(), n)\n",
    "for grams in bigrams:\n",
    "    print (grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f35c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "passage=\"\"\" The Marvel Cinematic Universe (MCU) is an American media franchise and shared universe centered on a series of superhero films produced by Marvel Studios. The films are based on characters that appear in American comic books published by Marvel Comics. The franchise also includes television series, short films, digital series, and literature. The shared universe, much like the original Marvel Universe in comic books, was established by crossing over common plot elements, settings, cast, and characters.\n",
    "\n",
    "Marvel Studios releases its films in groups called \"Phases\", with the first three phases collectively known as \"The Infinity Saga\" and the following three phases as \"The Multiverse Saga\". The first MCU film, Iron Man (2008), began Phase One, which culminated in the 2012 crossover film The Avengers. Phase Two began with Iron Man 3 (2013) and concluded with Ant-Man (2015). Phase Three began with Captain America: Civil War (2016) and concluded with Spider-Man: Far From Home (2019). Phase Four began with Black Widow (2021) and concluded with Black Panther: Wakanda Forever (2022). Ant-Man and the Wasp: Quantumania (2023) began Phase Five, which will end with Thunderbolts (2025), and Phase Six will begin with The Fantastic Four (2025). Phase Six and \"The Multiverse Saga\" will conclude with Avengers 5 (2026) and Avengers: Secret Wars (2027).\n",
    "\n",
    "Marvel Television expanded the universe to network television with Agents of S.H.I.E.L.D. on ABC in 2013 before further expanding to streaming television on Netflix and Hulu and to cable television on Freeform. They also produced the digital series Agents of S.H.I.E.L.D.: Slingshot. Marvel Studios began producing their own television series for streaming on Disney+, starting with WandaVision in 2021 as the beginning of Phase Four. They also expanded to television specials in Phase Four, known as Marvel Studios Special Presentations, the first of which was Werewolf by Night (2022). The MCU also includes tie-in comics published by Marvel Comics, a series of direct-to-video short films called Marvel One-Shots, and viral marketing campaigns for the films featuring the faux news programs WHIH Newsfront and The Daily Bugle.\n",
    "\n",
    "The franchise has been commercially successful, becoming one of the highest-grossing media franchises of all time, and generally received positive reviews. It has inspired other film and television studios to attempt similar shared universes and has also inspired several themed attractions, an art exhibit, television specials, literary material, multiple tie-in video games, and commercials.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "639b5d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The', 'Marvel')\n",
      "('Marvel', 'Cinematic')\n",
      "('Cinematic', 'Universe')\n",
      "('Universe', '(MCU)')\n",
      "('(MCU)', 'is')\n",
      "('is', 'an')\n",
      "('an', 'American')\n",
      "('American', 'media')\n",
      "('media', 'franchise')\n",
      "('franchise', 'and')\n",
      "('and', 'shared')\n",
      "('shared', 'universe')\n",
      "('universe', 'centered')\n",
      "('centered', 'on')\n",
      "('on', 'a')\n",
      "('a', 'series')\n",
      "('series', 'of')\n",
      "('of', 'superhero')\n",
      "('superhero', 'films')\n",
      "('films', 'produced')\n",
      "('produced', 'by')\n",
      "('by', 'Marvel')\n",
      "('Marvel', 'Studios.')\n",
      "('Studios.', 'The')\n",
      "('The', 'films')\n",
      "('films', 'are')\n",
      "('are', 'based')\n",
      "('based', 'on')\n",
      "('on', 'characters')\n",
      "('characters', 'that')\n",
      "('that', 'appear')\n",
      "('appear', 'in')\n",
      "('in', 'American')\n",
      "('American', 'comic')\n",
      "('comic', 'books')\n",
      "('books', 'published')\n",
      "('published', 'by')\n",
      "('by', 'Marvel')\n",
      "('Marvel', 'Comics.')\n",
      "('Comics.', 'The')\n",
      "('The', 'franchise')\n",
      "('franchise', 'also')\n",
      "('also', 'includes')\n",
      "('includes', 'television')\n",
      "('television', 'series,')\n",
      "('series,', 'short')\n",
      "('short', 'films,')\n",
      "('films,', 'digital')\n",
      "('digital', 'series,')\n",
      "('series,', 'and')\n",
      "('and', 'literature.')\n",
      "('literature.', 'The')\n",
      "('The', 'shared')\n",
      "('shared', 'universe,')\n",
      "('universe,', 'much')\n",
      "('much', 'like')\n",
      "('like', 'the')\n",
      "('the', 'original')\n",
      "('original', 'Marvel')\n",
      "('Marvel', 'Universe')\n",
      "('Universe', 'in')\n",
      "('in', 'comic')\n",
      "('comic', 'books,')\n",
      "('books,', 'was')\n",
      "('was', 'established')\n",
      "('established', 'by')\n",
      "('by', 'crossing')\n",
      "('crossing', 'over')\n",
      "('over', 'common')\n",
      "('common', 'plot')\n",
      "('plot', 'elements,')\n",
      "('elements,', 'settings,')\n",
      "('settings,', 'cast,')\n",
      "('cast,', 'and')\n",
      "('and', 'characters.')\n",
      "('characters.', 'Marvel')\n",
      "('Marvel', 'Studios')\n",
      "('Studios', 'releases')\n",
      "('releases', 'its')\n",
      "('its', 'films')\n",
      "('films', 'in')\n",
      "('in', 'groups')\n",
      "('groups', 'called')\n",
      "('called', '\"Phases\",')\n",
      "('\"Phases\",', 'with')\n",
      "('with', 'the')\n",
      "('the', 'first')\n",
      "('first', 'three')\n",
      "('three', 'phases')\n",
      "('phases', 'collectively')\n",
      "('collectively', 'known')\n",
      "('known', 'as')\n",
      "('as', '\"The')\n",
      "('\"The', 'Infinity')\n",
      "('Infinity', 'Saga\"')\n",
      "('Saga\"', 'and')\n",
      "('and', 'the')\n",
      "('the', 'following')\n",
      "('following', 'three')\n",
      "('three', 'phases')\n",
      "('phases', 'as')\n",
      "('as', '\"The')\n",
      "('\"The', 'Multiverse')\n",
      "('Multiverse', 'Saga\".')\n",
      "('Saga\".', 'The')\n",
      "('The', 'first')\n",
      "('first', 'MCU')\n",
      "('MCU', 'film,')\n",
      "('film,', 'Iron')\n",
      "('Iron', 'Man')\n",
      "('Man', '(2008),')\n",
      "('(2008),', 'began')\n",
      "('began', 'Phase')\n",
      "('Phase', 'One,')\n",
      "('One,', 'which')\n",
      "('which', 'culminated')\n",
      "('culminated', 'in')\n",
      "('in', 'the')\n",
      "('the', '2012')\n",
      "('2012', 'crossover')\n",
      "('crossover', 'film')\n",
      "('film', 'The')\n",
      "('The', 'Avengers.')\n",
      "('Avengers.', 'Phase')\n",
      "('Phase', 'Two')\n",
      "('Two', 'began')\n",
      "('began', 'with')\n",
      "('with', 'Iron')\n",
      "('Iron', 'Man')\n",
      "('Man', '3')\n",
      "('3', '(2013)')\n",
      "('(2013)', 'and')\n",
      "('and', 'concluded')\n",
      "('concluded', 'with')\n",
      "('with', 'Ant-Man')\n",
      "('Ant-Man', '(2015).')\n",
      "('(2015).', 'Phase')\n",
      "('Phase', 'Three')\n",
      "('Three', 'began')\n",
      "('began', 'with')\n",
      "('with', 'Captain')\n",
      "('Captain', 'America:')\n",
      "('America:', 'Civil')\n",
      "('Civil', 'War')\n",
      "('War', '(2016)')\n",
      "('(2016)', 'and')\n",
      "('and', 'concluded')\n",
      "('concluded', 'with')\n",
      "('with', 'Spider-Man:')\n",
      "('Spider-Man:', 'Far')\n",
      "('Far', 'From')\n",
      "('From', 'Home')\n",
      "('Home', '(2019).')\n",
      "('(2019).', 'Phase')\n",
      "('Phase', 'Four')\n",
      "('Four', 'began')\n",
      "('began', 'with')\n",
      "('with', 'Black')\n",
      "('Black', 'Widow')\n",
      "('Widow', '(2021)')\n",
      "('(2021)', 'and')\n",
      "('and', 'concluded')\n",
      "('concluded', 'with')\n",
      "('with', 'Black')\n",
      "('Black', 'Panther:')\n",
      "('Panther:', 'Wakanda')\n",
      "('Wakanda', 'Forever')\n",
      "('Forever', '(2022).')\n",
      "('(2022).', 'Ant-Man')\n",
      "('Ant-Man', 'and')\n",
      "('and', 'the')\n",
      "('the', 'Wasp:')\n",
      "('Wasp:', 'Quantumania')\n",
      "('Quantumania', '(2023)')\n",
      "('(2023)', 'began')\n",
      "('began', 'Phase')\n",
      "('Phase', 'Five,')\n",
      "('Five,', 'which')\n",
      "('which', 'will')\n",
      "('will', 'end')\n",
      "('end', 'with')\n",
      "('with', 'Thunderbolts')\n",
      "('Thunderbolts', '(2025),')\n",
      "('(2025),', 'and')\n",
      "('and', 'Phase')\n",
      "('Phase', 'Six')\n",
      "('Six', 'will')\n",
      "('will', 'begin')\n",
      "('begin', 'with')\n",
      "('with', 'The')\n",
      "('The', 'Fantastic')\n",
      "('Fantastic', 'Four')\n",
      "('Four', '(2025).')\n",
      "('(2025).', 'Phase')\n",
      "('Phase', 'Six')\n",
      "('Six', 'and')\n",
      "('and', '\"The')\n",
      "('\"The', 'Multiverse')\n",
      "('Multiverse', 'Saga\"')\n",
      "('Saga\"', 'will')\n",
      "('will', 'conclude')\n",
      "('conclude', 'with')\n",
      "('with', 'Avengers')\n",
      "('Avengers', '5')\n",
      "('5', '(2026)')\n",
      "('(2026)', 'and')\n",
      "('and', 'Avengers:')\n",
      "('Avengers:', 'Secret')\n",
      "('Secret', 'Wars')\n",
      "('Wars', '(2027).')\n",
      "('(2027).', 'Marvel')\n",
      "('Marvel', 'Television')\n",
      "('Television', 'expanded')\n",
      "('expanded', 'the')\n",
      "('the', 'universe')\n",
      "('universe', 'to')\n",
      "('to', 'network')\n",
      "('network', 'television')\n",
      "('television', 'with')\n",
      "('with', 'Agents')\n",
      "('Agents', 'of')\n",
      "('of', 'S.H.I.E.L.D.')\n",
      "('S.H.I.E.L.D.', 'on')\n",
      "('on', 'ABC')\n",
      "('ABC', 'in')\n",
      "('in', '2013')\n",
      "('2013', 'before')\n",
      "('before', 'further')\n",
      "('further', 'expanding')\n",
      "('expanding', 'to')\n",
      "('to', 'streaming')\n",
      "('streaming', 'television')\n",
      "('television', 'on')\n",
      "('on', 'Netflix')\n",
      "('Netflix', 'and')\n",
      "('and', 'Hulu')\n",
      "('Hulu', 'and')\n",
      "('and', 'to')\n",
      "('to', 'cable')\n",
      "('cable', 'television')\n",
      "('television', 'on')\n",
      "('on', 'Freeform.')\n",
      "('Freeform.', 'They')\n",
      "('They', 'also')\n",
      "('also', 'produced')\n",
      "('produced', 'the')\n",
      "('the', 'digital')\n",
      "('digital', 'series')\n",
      "('series', 'Agents')\n",
      "('Agents', 'of')\n",
      "('of', 'S.H.I.E.L.D.:')\n",
      "('S.H.I.E.L.D.:', 'Slingshot.')\n",
      "('Slingshot.', 'Marvel')\n",
      "('Marvel', 'Studios')\n",
      "('Studios', 'began')\n",
      "('began', 'producing')\n",
      "('producing', 'their')\n",
      "('their', 'own')\n",
      "('own', 'television')\n",
      "('television', 'series')\n",
      "('series', 'for')\n",
      "('for', 'streaming')\n",
      "('streaming', 'on')\n",
      "('on', 'Disney+,')\n",
      "('Disney+,', 'starting')\n",
      "('starting', 'with')\n",
      "('with', 'WandaVision')\n",
      "('WandaVision', 'in')\n",
      "('in', '2021')\n",
      "('2021', 'as')\n",
      "('as', 'the')\n",
      "('the', 'beginning')\n",
      "('beginning', 'of')\n",
      "('of', 'Phase')\n",
      "('Phase', 'Four.')\n",
      "('Four.', 'They')\n",
      "('They', 'also')\n",
      "('also', 'expanded')\n",
      "('expanded', 'to')\n",
      "('to', 'television')\n",
      "('television', 'specials')\n",
      "('specials', 'in')\n",
      "('in', 'Phase')\n",
      "('Phase', 'Four,')\n",
      "('Four,', 'known')\n",
      "('known', 'as')\n",
      "('as', 'Marvel')\n",
      "('Marvel', 'Studios')\n",
      "('Studios', 'Special')\n",
      "('Special', 'Presentations,')\n",
      "('Presentations,', 'the')\n",
      "('the', 'first')\n",
      "('first', 'of')\n",
      "('of', 'which')\n",
      "('which', 'was')\n",
      "('was', 'Werewolf')\n",
      "('Werewolf', 'by')\n",
      "('by', 'Night')\n",
      "('Night', '(2022).')\n",
      "('(2022).', 'The')\n",
      "('The', 'MCU')\n",
      "('MCU', 'also')\n",
      "('also', 'includes')\n",
      "('includes', 'tie-in')\n",
      "('tie-in', 'comics')\n",
      "('comics', 'published')\n",
      "('published', 'by')\n",
      "('by', 'Marvel')\n",
      "('Marvel', 'Comics,')\n",
      "('Comics,', 'a')\n",
      "('a', 'series')\n",
      "('series', 'of')\n",
      "('of', 'direct-to-video')\n",
      "('direct-to-video', 'short')\n",
      "('short', 'films')\n",
      "('films', 'called')\n",
      "('called', 'Marvel')\n",
      "('Marvel', 'One-Shots,')\n",
      "('One-Shots,', 'and')\n",
      "('and', 'viral')\n",
      "('viral', 'marketing')\n",
      "('marketing', 'campaigns')\n",
      "('campaigns', 'for')\n",
      "('for', 'the')\n",
      "('the', 'films')\n",
      "('films', 'featuring')\n",
      "('featuring', 'the')\n",
      "('the', 'faux')\n",
      "('faux', 'news')\n",
      "('news', 'programs')\n",
      "('programs', 'WHIH')\n",
      "('WHIH', 'Newsfront')\n",
      "('Newsfront', 'and')\n",
      "('and', 'The')\n",
      "('The', 'Daily')\n",
      "('Daily', 'Bugle.')\n",
      "('Bugle.', 'The')\n",
      "('The', 'franchise')\n",
      "('franchise', 'has')\n",
      "('has', 'been')\n",
      "('been', 'commercially')\n",
      "('commercially', 'successful,')\n",
      "('successful,', 'becoming')\n",
      "('becoming', 'one')\n",
      "('one', 'of')\n",
      "('of', 'the')\n",
      "('the', 'highest-grossing')\n",
      "('highest-grossing', 'media')\n",
      "('media', 'franchises')\n",
      "('franchises', 'of')\n",
      "('of', 'all')\n",
      "('all', 'time,')\n",
      "('time,', 'and')\n",
      "('and', 'generally')\n",
      "('generally', 'received')\n",
      "('received', 'positive')\n",
      "('positive', 'reviews.')\n",
      "('reviews.', 'It')\n",
      "('It', 'has')\n",
      "('has', 'inspired')\n",
      "('inspired', 'other')\n",
      "('other', 'film')\n",
      "('film', 'and')\n",
      "('and', 'television')\n",
      "('television', 'studios')\n",
      "('studios', 'to')\n",
      "('to', 'attempt')\n",
      "('attempt', 'similar')\n",
      "('similar', 'shared')\n",
      "('shared', 'universes')\n",
      "('universes', 'and')\n",
      "('and', 'has')\n",
      "('has', 'also')\n",
      "('also', 'inspired')\n",
      "('inspired', 'several')\n",
      "('several', 'themed')\n",
      "('themed', 'attractions,')\n",
      "('attractions,', 'an')\n",
      "('an', 'art')\n",
      "('art', 'exhibit,')\n",
      "('exhibit,', 'television')\n",
      "('television', 'specials,')\n",
      "('specials,', 'literary')\n",
      "('literary', 'material,')\n",
      "('material,', 'multiple')\n",
      "('multiple', 'tie-in')\n",
      "('tie-in', 'video')\n",
      "('video', 'games,')\n",
      "('games,', 'and')\n",
      "('and', 'commercials.')\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "bigrams = ngrams(passage.split(), n)\n",
    "for grams in bigrams:\n",
    "    print (grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091a1eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e73b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaeacde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "122f58f8",
   "metadata": {},
   "source": [
    "# N-gram Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d811906",
   "metadata": {},
   "source": [
    "Let’s take the example of a sentence completion system. This system suggests words which could be used next in a given sentence. Suppose I give the system the sentence “Thank you so much for your” and expect the system to predict what the next word will be. Now you and me both know that the next word is “help” with a very high probability. But how will the system know that?\n",
    "\n",
    "One important thing to note here is that, as for any other artificial intelligence or machine learning model, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d2f029",
   "metadata": {},
   "source": [
    "### we need to train the model with a huge corpus of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bc470b",
   "metadata": {},
   "source": [
    "Once we do that, the system, or the NLP model will have a pretty good idea of the “probability” of the occurrence of a word after a certain word. So hoping that we have trained our model with a huge corpus of data, we’ll assume that the model gave us the correct answer.\n",
    "\n",
    "I spoke about the probability a bit there, but let’s now build on that. When we’re building an NLP model for predicting words in a sentence, *the probability of the occurrence of a word in a sequence of words is what matters.* And how do we measure that? Let’s say we’re working with a bigram model here, and we have the following sentences as the training corpus:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8578c4ed",
   "metadata": {},
   "source": [
    "> 1: Thank you so much for your help.\n",
    "\n",
    "> 2: I really appreciate your help.\n",
    "\n",
    "> 3: Excuse me, do you know what time it is?\n",
    "\n",
    "> 4: I’m really sorry for not inviting you.\n",
    "\n",
    "> 5: I really like your watch.\n",
    "\n",
    "> 6: I really like the pizza.\n",
    "\n",
    "> 7: I like roses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35e76d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count(really like) /count(like)\n",
    "\n",
    "2 / 3\n",
    "event : after really we are getting\n",
    "Sample space: how many times we are getting really\n",
    "\n",
    "P(Number )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784e8ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Tea biscuits)/ Tea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b38c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "20 times tea\n",
    "\n",
    "8 times tea with biscuit\n",
    "\n",
    "\n",
    "30 times biscuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f187f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf70ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b595d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1536b6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9beb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "really ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23977ee",
   "metadata": {},
   "source": [
    "Let’s suppose that after training our model with this data, I want to write the sentence “I really like your garden.” Now because this is a bigram model, the model will learn the occurrence of every two words, to determine the probability of a word occurring after a certain word. For example, from the 2nd, 4th, and the 5th sentence in the example above, we know that after the word “really” we can see either the word “appreciate”, “sorry”, or the word “like” occurs. So the model will calculate the probability of each of these sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165e71ae",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Suppose we’re calculating the probability of word “w1” occurring after the word “w2,” then the formula for this is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c573c8ce",
   "metadata": {},
   "source": [
    "> count(w2 w1) / count(w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af6aede",
   "metadata": {},
   "source": [
    "which is the number of times the words occurs in the required sequence, divided by the number of the times the word before the expected word occurs in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577e4f31",
   "metadata": {},
   "source": [
    "From our example sentences, let’s calculate the probability of the word “like” occurring after the word “really”:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9411a0f2",
   "metadata": {},
   "source": [
    "> count(really like) / count(really)\n",
    "    \n",
    "    = 1 / 3\n",
    "    \n",
    "    = 0.33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8643d29f",
   "metadata": {},
   "source": [
    "> count(really appreciate) / count(really)\n",
    "\n",
    "    = 1 / 3\n",
    "\n",
    "    = 0.33\n",
    "\n",
    "    count(really sorry) / count(really)\n",
    "\n",
    "    = 1 / 3\n",
    "\n",
    "    = 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9abd80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {(\"really\", \"like\"): 0.40, \n",
    "    (\"really\",\"appreciate\"): 0.27, \n",
    "     (\"really\", \"sorry\"): 0.33\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50d52f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('really', 'like'): 0.33,\n",
       " ('really', 'appreciate'): 0.33,\n",
       " ('really', 'sorry'): 0.33}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5406664",
   "metadata": {},
   "source": [
    "So when I type the phrase “I really,” and expect the model to suggest the next word, it’ll get the right answer only once out of three times, because the probability of the correct answer is only 1/3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3118ee6c",
   "metadata": {},
   "source": [
    "As an another example, if my input sentence to the model is “Thank you for inviting,” and I expect the model to suggest the next word, it’s going to give me the word “you,” because of the example sentence 4. That’s the only example the model knows. As you can imagine, if we give the model a bigger corpus (or a bigger dataset) to train on, the predictions will improve a lot. Similarly, we’re only using a bigram here. We can use a trigram or even a 4-gram to improve the model’s understanding of the probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c926a6d",
   "metadata": {},
   "source": [
    "### Using these n-grams and the probabilities of the occurrences of certain words in certain sequences could improve the predictions of auto completion systems. Similarly, we can use NLP and n-grams to train voice-based personal assistant bots. \n",
    "\n",
    "For example, using a 3-gram or trigram training model, a bot will be able to understand the difference between sentences such as “what’s the temperature?” and “set the temperature.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e28aa23",
   "metadata": {},
   "source": [
    "> What's the temperature.\n",
    "\n",
    "> Set the temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c75ef7",
   "metadata": {},
   "source": [
    "bigram\n",
    "\n",
    "[(What's the), (the temperature)]\n",
    "\n",
    "[(Set the), (the temperature)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76011a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
